\chapter{Introduction}

Computer networking has a firm presence in many modern applications. Applications for social media, video streaming, and many other types of content rely on computer networking. Whether the communication be via a server using the Hypertext Transfer Protocol (HTTP) or a server using the WebSocket Protocol (WebSockets), the common denominator is the Transmission Control Protocol (TCP) \cite{fielding1999hypertext,fette2011websocket}. As an underlying protocol to HTTP and WebSockets, TCP provides the foundation for these higher level protocols, as well as other protocols that use TCP, to ensure reliability in communication and data integrity \cite{cerf1978specification}. However, these assurances offered by TCP have associated costs that directly impact transfer rate and network utilization, or bandwidth.

Many proposed methods focused on optimizing TCP by modifying the behavior of congestion control, fine tuning how packets are tracked, and increasing the responsiveness to packet loss \cite{brakmo1995tcp,wei2006fast,xu2004binary,ha2008cubic}. These solutions were able to improve the transfer rate over TCP without compromising communication reliability. As physical connections increase in bandwidth, optimizing TCP may not be enough to maximize network utilization.

A different approach has been to focus on creating new higher level protocols, or Application layer protocols. Works like \cite{Allman1995,Allman1997,Sivakumar2000psockets} used multiple TCP connections in parallel to try and improve performance without sacrificing reliability in communication. Parallelization poses two major challenges. The first is the additional work required of the application to handle multithreading in a way that addresses race conditions, deadlocks, and synchronicity. The second challenge is directly related to the degree of parallelism of a machine. If a machine's central processing unit (CPU) can support four threads in parallel, the application has to ensure that all four threads are busy with work in order to ensure that the CPU is being fully utilized. In the context of I/O operations, such as network communication, a thread that performs an I/O operation will become blocked \cite{rhoden2014operating,lucovsky1998system,richter2012clr}. Threads that are blocked are unable to perform any CPU computations and thus the CPU is not fully utilized \cite{rhoden2014operating}.

An emerging idea for addressing underutilized networks has been to use UDP as the transport protocol. In works \cite{He2002,Fan2010,Aspera2016,Meiss2007,gu2007udt}, a UDP transport is leveraged to increase the transfer rate beyond the capabilities of TCP. The reason for this is, unlike TCP, UDP does not employ any type of congrestion control or packet recovery \cite{postel1980user}. However, this means that in scenarios where the network is already congested, packets may be lost because UDP will attempt to send packets with no regard for the network conditions. Solutions like these that are UDP-based have to tackle the issue of communication reliability themselves. However, with increasing capabilities of physical connections with respect to bandwidth, a different challenge presents itself regarding packet loss.

Aspera has noted that the challenge with computer networking is not so much with slow physical connections, but is instead with the end systems not being fast enough for the connection \cite{Fan2010,Aspera2016}. The path Aspera took involved building a custom end system that could operate faster to handle faster connections. The decision Aspera made begs the question, is it possible to achieve a faster end system by using a more generic technology?

This work reviews an experimental protocol called Multi-Channel Data Transfer Protocol (MCDTP) and its implementation (MCDTPi). The experimental protocol and implementation seek to address the aforementioned question by using asynchronous technology to support multiple data transfer channels. Utilization of multiple channels increases the amount of buffer space for receiving packets allowing for the Application layer to handle more data. This report discusses the design of the protocol, the architecture of the implementation, the performance of MCDTP, and the challenges faced by this project. The goal of this project is to evaluate the following question: can asynchronous technology provide performance improvements to end systems?
